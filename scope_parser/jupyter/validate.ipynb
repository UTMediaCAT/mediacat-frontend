{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.378613Z",
     "start_time": "2020-11-16T16:49:06.865525Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import sys\n",
    "import chardet    \n",
    "import validators\n",
    "import scope_parser as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.385275Z",
     "start_time": "2020-11-16T16:49:07.381144Z"
    }
   },
   "outputs": [],
   "source": [
    "# check the input file should be csv file\n",
    "def is_csv(filename):\n",
    "    \"\"\"\n",
    "    check input file is csv or not, if it is, change it to unicode\n",
    "    :param filename: a csv file name\n",
    "    :rtype: Boolean if it is correct, exit process if it isn't csv\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # try to read csv file\n",
    "        df = pd.read_csv(filename)\n",
    "        # restore it as unicode\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        return True\n",
    "    except(Exception):\n",
    "        print(\"Input file is not csv or doesn't exist such csv\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.392783Z",
     "start_time": "2020-11-16T16:49:07.388648Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_unicode(filename):\n",
    "    \"\"\"\n",
    "    check the csv file is unicode or not\n",
    "    :param filename: a csv file name\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as detect_file_encoding:\n",
    "        detection = chardet.detect(detect_file_encoding.read())\n",
    "        print('Chardet:', detection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.402210Z",
     "start_time": "2020-11-16T16:49:07.399106Z"
    }
   },
   "outputs": [],
   "source": [
    "def url_is_alive(url):\n",
    "    \"\"\"\n",
    "    Checks that a given URL is reachable.\n",
    "    :param url: A URL\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    if validators.url(url) == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.408327Z",
     "start_time": "2020-11-16T16:49:07.403957Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_domain(df):\n",
    "    \"\"\"\n",
    "    Checks that a given df's url is reachable and return invalid dataframe.\n",
    "    :param df: A dataframe\n",
    "    :rtype: a dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    domain = df.loc[df[\"Type\"] == \"News Source\"].copy(deep=True) \n",
    "    result = domain[\"Source\"].apply(url_is_alive)\n",
    "    domain.loc[:,'domain_valid'] = result\n",
    "    domain = domain.loc[domain[\"domain_valid\"] == False]  # nopep8\n",
    "    del domain['domain_valid']\n",
    "    return domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.415290Z",
     "start_time": "2020-11-16T16:49:07.411574Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_ATH(df):\n",
    "    \"\"\"\n",
    "    Checks that all Associated Twitter Handle is valid or not \n",
    "    and return invalid dataframe.\n",
    "    :param df: A dataframe\n",
    "    :rtype: a dataframe\n",
    "    \"\"\"\n",
    "    return(df.loc[~(df[\"Associated Twitter Handle\"].isnull() | df[\"Associated Twitter Handle\"].str.startswith('@'))])   # nopep8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.420593Z",
     "start_time": "2020-11-16T16:49:07.417073Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_Type(df):  # silence pyflakes\n",
    "    \"\"\"\n",
    "    find every rows that Type is not \"News Source\" or \"Twitter Handle\" \n",
    "    and return invalid rows as a new dataframe.\n",
    "    :param df: A dataframe\n",
    "    :rtype: a dataframe\n",
    "    \"\"\"\n",
    "    new = df.loc[~((df[\"Type\"] == \"Twitter Handle\") | (df[\"Type\"] == \"News Source\"))]\n",
    "    return(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.426076Z",
     "start_time": "2020-11-16T16:49:07.422543Z"
    }
   },
   "outputs": [],
   "source": [
    "# find the source is incorrect format and return index\n",
    "def check_Source(df):\n",
    "    \"\"\"\n",
    "    Checks that all source(Twitter Handle part) is valid or not \n",
    "    and return invalid rows as a new dataframe.\n",
    "    :param df: A dataframe\n",
    "    :rtype: a dataframe\n",
    "    \"\"\"    \n",
    "    new = df.loc[df[\"Type\"] == \"Twitter Handle\"]\n",
    "    return(new.loc[~(df[\"Source\"].str.startswith('@'))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.433490Z",
     "start_time": "2020-11-16T16:49:07.430035Z"
    }
   },
   "outputs": [],
   "source": [
    "def insert_error_type(error_name):\n",
    "    \"\"\"\n",
    "    Create a new dataframe stand for error name\n",
    "    :param error_name: A string of error name\n",
    "    :rtype: A dataframe\n",
    "    \"\"\"    \n",
    "    \n",
    "    df = pd.DataFrame({'Source': [error_name],\n",
    "                       \"RSS feed URLs (where available)\": np.nan,\n",
    "                        'Type': np.nan,\n",
    "                        'Tags': np.nan,\n",
    "                        'Associated Twitter Handle': np.nan,\n",
    "                        'Associated Publisher': np.nan,\n",
    "                        'Name': np.nan,        \n",
    "                        'Text aliases': np.nan})\n",
    "    return(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.446151Z",
     "start_time": "2020-11-16T16:49:07.436444Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validation(file):\n",
    "    \"\"\"\n",
    "    validate file is valid or not, \n",
    "    if it is valid, generate twitter.csv and domain.csv\n",
    "    if it is invalid, print error type and size and generate error.csv\n",
    "    :param df: A dataframe\n",
    "    :rtype: None\n",
    "    \"\"\"    \n",
    "    # check whether the file has error or not\n",
    "    error_key = 0\n",
    "    # test does it is csv file and convert file into unicode\n",
    "    is_csv(file)\n",
    "    print(\"It is valid csv file\")\n",
    "    # read the file as data frame\n",
    "    df = pd.read_csv(file)\n",
    "    # create a new_dataframe for error records\n",
    "    Error = pd.DataFrame(columns=['Source', 'RSS feed URLs (where available)', 'Type','Tags','Associated Twitter Handle','Associated Publisher','Name','Text aliases']) # nopep8\n",
    "\n",
    "    print(\"check Type\")\n",
    "    error_type = check_Type(df)\n",
    "    print(\"There are %d lines with Type errors\" % error_type.index.size)\n",
    "    if error_type.index.size != 0:\n",
    "        error_key = 1\n",
    "        type_error_name = insert_error_type(\"Type error\")\n",
    "        Error = Error.append(type_error_name)\n",
    "        Error = Error.append(error_type)\n",
    "    \n",
    "    print(\"check Url\")\n",
    "    error_Url = check_domain(df)\n",
    "    print(\"There are %d lines with invaild Url errors\" % error_Url.index.size)\n",
    "    if error_Url.index.size != 0:\n",
    "        error_key = 1\n",
    "        Url_error_name = insert_error_type(\"URL error\")\n",
    "        Error = Error.append(Url_error_name)\n",
    "        Error = Error.append(error_Url)\n",
    "        \n",
    "    print(\"check Associate Twitter Handle\") \n",
    "    error_ATH = check_ATH(df)\n",
    "\n",
    "    print(\"There are %d lines with incorrect Associate Twitter Handle errors\" % error_ATH.index.size)\n",
    "    if error_ATH.index.size != 0:\n",
    "        error_key = 1\n",
    "        ATH_error_name = insert_error_type(\"Associate Twitter Handle error\")\n",
    "        Error = Error.append(ATH_error_name)\n",
    "        Error = Error.append(error_ATH)\n",
    "        \n",
    "    print(\"check Twitter Handle\")\n",
    "    error_TH = check_Source(df)\n",
    "    print(\"There are %d lines with incorrect Twitter Handle errors\" % error_TH.index.size)\n",
    "    if error_TH.index.size != 0:\n",
    "        error_key = 1\n",
    "        TH_error_name = insert_error_type(\"Twitter Handle error\")\n",
    "        Error = Error.append(TH_error_name)\n",
    "        Error = Error.append(error_TH)\n",
    "     \n",
    "    # if it has error, generate error.csv\n",
    "    if error_key == 1:\n",
    "        print(\"csv exists some errors, please fix it\")\n",
    "        print(\"generate error.csv\")\n",
    "        Error.to_csv('error.csv', index=True, encoding='utf-8-sig')\n",
    "        return None\n",
    "    else:\n",
    "        sp.scope_parser(file)\n",
    "        print(\"Valid\")\n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:49:07.507456Z",
     "start_time": "2020-11-16T16:49:07.447785Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is valid csv file\n",
      "check Type\n",
      "There are 3 lines with Type errors\n",
      "check Url\n",
      "There are 34 lines with invaild Url errors\n",
      "check Associate Twitter Handle\n",
      "There are 0 lines with incorrect Associate Twitter Handle errors\n",
      "check Twitter Handle\n",
      "There are 2 lines with incorrect Twitter Handle errors\n",
      "csv exists some errors, please fix it\n",
      "generate error.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #inFile = sys.argv[1]\n",
    "    validation(\"input_scope_final.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
